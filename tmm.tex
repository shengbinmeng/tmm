
%% tmm.tex
%% by Shengbin Meng

% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option 
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
%\documentclass[journal,draftclsnofoot,onecolumn]{IEEEtran}
\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}


 
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
   \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
   \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
   \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex


% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/


% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.


% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% added by shengbin
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{algorithm}


% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
\title{Adaptive Video Streaming System with PID-Based Quality Control and Optimized Bitstream Extraction}

% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%
\author{Shengbin~Meng,~Jun~Sun,~Yizhou~Duan~and~Zongming~Guo % <-this % stops a space
\thanks{S. Meng is with the Institute of Computer Science and Technology, Peking University, Beijing%
, 100080 China e-mail: shengbin@pku.edu.cn.}% <-this % stops a space
\thanks{J. Sun, Y. Duan, Z. Guo are with the Institute of Computer Science and Technology, Peking University.}% <-this % stops a space
\thanks{Manuscript received September 15, 2014}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
%\markboth{IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY,~Vol.~11, No.~4, December~2013}%
%{Shengbin Meng \MakeLowercase{\textit{et al.}}: Efficient H.264/SVC Bitstream Extraction Based on a Linear Error Model}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2012 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}



\begin{document}

\listoffigures

\listoftables


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
In order to meet the challenge brought by bandwidth fluctuation of the user's network, modern video streaming systems tend to be adaptive, i.e., able to adjust the video quality according to available bandwidth. This paper implements such an adaptive video streaming system which utilizes the Scalable Video Coding (SVC) technology, and gives novel solutions for two key problems within the system. First, a quality control algorithm is proposed for the video streaming system to adjust its video quality along with the real bandwidth change. The algorithm is based on the Proportional-Integral-Derivative (PID) control method and designed to deliver best video quality with least quality fluctuation. Second, an efficient solution is present for the bitstream extraction problem, which aims to select an optimal sub-stream from the whole SVC video bitstream under given bitrate constraint. The solution features a linear error model to estimate the distortion caused by discarding any combination of data packets, and a greedy algorithm scheme to assign each data packet a priority value for Rate-Distortion optimized extraction. Experimental results show that the PID-based quality control algorithm can drastically reduce the quality fluctuation while still keeping a high quality level, and the bitstream extraction method can achieve a significant PSNR gain compared to existing reference extractors, without computational complexity increment. The system is currently running at the online video website www.7dlive.com and proves to be practically effective.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
video streaming, quality control, bitstream extraction, distortion model, Scalable Video Coding, PID.
\end{IEEEkeywords}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
\label{sec:intro}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
\IEEEPARstart{V}{ideo} streaming applications are becoming more and more popular on the Internet. Examples of the most common usage scenarios include VOD (Video On Demand), live broadcasting, video-based online education, etc. In these applications, video data is constantly delivered to different clients over various transmission channels, and the client media player can begin playing the video before the entire file has been transmitted. Among other features, video streaming makes it easy to watch video anywhere and anytime, and is an increasingly important way for people to consume video content.

One of the biggest challenge for video streaming is the variety of users' network environment. A user may use different types of network (Ethernet, Wi-Fi, Cellular, etc) and may also switch from one type to another (e.g., from Wi-Fi to cellular network) on going. Even in the same network, the user's bandwidth may change from time to time, influenced by the overall traffic. During such an environment, bandwidth fluctuation is inevitable. If the video is streamed at a constant bitrate, it would be difficult or impossible for the client to keep a non-paused smooth playing. Therefore, to achieve better watching experience for users with various network environment, the video's bitrate or quality should be able to adjust according to the bandwidth change. In other words, the video streaming system needs to be adaptive.

There are generally two options to enable adaptive video streaming. The first option is called simulcast, where several independent bitstreams with different video quality are stored at the server, and the client selects one of them according to currently available bandwidth. Dynamic Adaptive Streaming over HTTP (DASH) \cite{DASH}, which is standardized by the Moving Picture Expert Group (MPEG), belongs to this option. The second option is to adopt the Scalable Video Coding (SVC) \cite{SVC} technology, which allows efficient scalability of video bitrate and quality with only one single bitstream. The generally-known term SVC usually refers to the scalable extension of the H.264/AVC video coding standard \cite{SVCOverview}. In SVC, a video bitstream is composed of Network Abstract Layer Units (NALUs), which are separated into multiple layers: one base layer for basic video quality and multiple enhancement layers for video quality improvement. By discarding NALUs of the enhancement layers, the bitstream can be extracted to provide the most appropriate data rate and video quality as required.

The advantage of simulcast systems is that they need little modification of existing infrastructure and therefore are easy to deploy. Most commercial video websites, YouTube \cite{YouTube} for instance, use this option to enable quality adaptation. However, the adaptive range and granularity simulcast provides is strictly limited to the number of streams (YouTube videos have 5 quality levels at most: 240p, 360p, 480p, 720p and 1080p), and the processing and storage of multiple video streams significantly increase time and space cost. SVC streaming systems, on the contrary, do not have above shortcomings. An SVC video bitstream can be extracted at the granularity of one NALU (a very small partition of data), and thus can provide seamless scalability and adaptation. Besides, performance analysis \cite{SVCPerformance} shows that SVC also has much higher coding efficiency than simulcast, despite some computation and bitrate overhead comparing with single layer stream. Therefore, SVC is considered to be a better choice for adaptive video streaming systems. While our work in this paper can be partly used in a simulcast system, we will mainly focus on building an adaptive streaming system using SVC.

To guarantee good performance of SVC streaming system, there are two important issues that need to be addressed well. First is quality control, and the second is bitstream extraction. Quality control means controlling the video quality (as well as the bitrate) to follow the change of bandwidth. Once the bandwidth has changed, the quality control algorithm should determine a bitrate suitable for the current bandwidth. Given this bitrate, how to extract data from the whole SVC stream to form an optimal sub-stream becomes the bitstream extraction problem. Optimized bitstream extraction aims to select a subset of NALUs (or packets) which represents video with best quality, or minimal distortion, under the constrain of the given bitrate. It should be noted that, bitstream extraction is not only useful in adaptive video streaming, but also in other SVC application scenarios where part of data needs to be obtained or kept, e.g., the archiving of surveillance video.

In this paper, we propose novel solutions for these two issues and construct an efficient adaptive video streaming system. Apple Darwin Streaming Server (DSS) \cite{DSS}, which has been widely used to collect, cache, schedule and transmit multimedia contents in practice, is chosen as the basis of the system. We modified the original DSS project and added SVC support to it, for the purpose of both research and application. A new quality control algorithm based on the Proportional-Integral-Derivative (PID) control concept is proposed to replace the native one in DSS, and achieves higher average quality level with less quality fluctuation. For the bitstream extraction problem, we propose a linear error model to directly estimate pixel value errors before MSE or PSNR is calculated. This model enables us to accurately estimate the distortion caused by discarding any combination of packets. Based on that, we design a greedy algorithm to assign priority for each quality enhancement packet according to its rate-distortion (R-D) impact. The priority value of each packet can be stored in the bitstream and used for optimized extraction. The proposed algorithms perform well in experiments and the quality control algorithm is also implemented in the practical streaming system we construct and proved quite effective.

The rest of this paper is organized as follows. In section \ref{sec:analysis}, we analyze the problems in detail and introduce some related works on them. Then in section \ref{sec:quality-control}, the proposed quality control algorithm is formulated and explained with term definitions and parameters selection. After that, we propose the solution for the bitstream extraction problem in \ref{sec:bit-extraction}. Section \ref{sec:experiment} lists the experimental results and compares our proposed solution with others. Finally, in section \ref{sec:conclusion}, we conclude this paper's work and point out its promising applications and extensions in the future.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Analysis and Related Works}
\label{sec:analysis}

In this section, we analyze the two most concerned problems in SVC adaptive streaming, i.e., quality control and bitstream extraction, and introduce some existing related works on them.

\subsection{Quality Control}

For a quality control algorithm, there are three targets that should be achieved. First is to ensure the continuity of video playing. In real-time streaming system, each data packet has its own playtime, which is also regarded as the deadline of the transmission. If the packet does not arrive at client side before the deadline, the media player will be paused due to lack of data, and that should be avoided. The second is to keep a smooth video quality. Although network conditions may change rapidly, it is necessary for the streamed video to maintain a relatively stable quality level, since frequent change of video quality will lead to poor user experience. The third target is to make the video quality as good as possible. In other words, the available bandwidth should be fully utilized. Suppose we keep sending video data in a low bitrate (with low video quality as well), neither the playback pause nor any quality fluctuation will likely happen. However, a low video quality is certainly not what we want.

The state-of-art solutions to avoid video pause in client media player mainly focus on how to select and schedule the video packets. In \cite{Gao06}, K. Gao et al. proposed a priority based scheduling strategy which guarantees packets of higher importance will be transmitted earlier. Among the packets with the same priority, those having the earliest deadline will be transmitted first. A similar solution is proposed in \cite{Schierl10}, where video data is pre-buffered in several buffers of different priorities. Whenever re-buffering occurs, quality will be degraded to a lower level to meet the time and rate constraint. Although the priority based scheduling strategies perform well in maintaining a non-paused video playing, they do not take quality fluctuation into account. As a result, users may still suffer from the frequent fluctuation of video quality.

In DSS, quality control is implemented by monitoring packet delay (the difference between current time and the playing time of this packet). When a new packet is ready to be sent to streaming buffer, DSS checks the delay of it and compares this delay with some pre-set critical time thresholds to judge whether and how violently the quality change should be made. This algorithm can reduce quality fluctuation to some degree. However, it only provides conservative quality change, which makes its reaction so slow that sometimes media player may have already stopped due to lack of video data before quality drops. Furthermore, this algorithm has no knowledge of the bandwidth change so it cannot accurately adjust the video quality. Therefore, quality oscillation is inevitable in this algorithm.

\subsection{Bitstream Extraction}

SVC bitstream extraction is substantially a combinatorial optimization problem. More specifically, it is in the form of ``0-1 Knapsack Problem". Each NALU data packet can be treated as an object with certain value (its contribution to the video quality) and weight (its size). The solving process is mainly to decide whether or not a packet should be included in the final extracted sub-stream; or in the term of ``0-1 Knapsack Problem", to choose which object to pack up.

Generally, the optimal solution of a typical ``0-1 Knapsack Problem" can be found using the dynamic programming algorithm. However, this is not operational for the bitstream extraction problem, mainly due to the dependence between packets. First, the value of a packet is not obvious and certain, since a packet's contribution to video quality may depend on the other packets. Second, the subset of packets to be extracted cannot be chosen arbitrarily, since if a packet is included, all the packets it depends on must also be included. In fact, to the best of our knowledge, no method presented in the literature claims to find the optimal solution of the SVC bitstream extraction problem. All the effort is made to obtain a solution that is as good as possible.

In \cite{Amonou07}, Amonou et al. proposed a bitstream extraction framework based on the concept of \textit{Quality Layers}. This framework has been adopted by the SVC reference software, i.e., JSVM  \cite{JSVM}, and achieves better R-D performance compared with the basic extractor of JSVM. In Amonou's framework, a Quality Layer value, which reflects a packet's R-D impact, is calculated and used for R-D optimized bitstream extraction. The process of obtaining distortion impact of every packet is extremely time consuming, and the distortion estimation accuracy can also be further improved. So other distortion/error models were proposed to either reduce the computational complexity or improve the estimation accuracy. Sun et al. \cite{Sun09} and Maani et al. \cite{Maani09} constructed models to calculate distortion based on the drift propagation between frames. Sun et al.'s method is almost as good as JSVM in regard of performance, but has much reduced complexity. Maani et al.'s model can achieve better estimation accuracy than JSVM; however, since it is  a training-based model, more computation is needed to get robust model parameters.

In our previous work \cite{Zhang12}, we noticed the mismatch between quadratic calculations in distortion criteria like MSE or PSNR and the essential linear operations in the coding process, and proposed a linear error model to directly estimate pixel value errors before MSE or PSNR is calculated. The linear error model exploits the linear feature of pixel value errors and achieves good performance in distortion estimation and bitstream extraction with reference. However, this work assumes that the original video sequence is available for reference, which is not always true. Adaptation to handle the special characteristic of the no-reference case is lacking, and is included in this paper.

The following of this paper will present solutions for the above problems, and lay a solid foundation for a practical adaptive video streaming system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PID-based Quality Control Algorithm}
\label{sec:quality-control}

PID control \cite{PID}\cite{Astrom02} is a control loop feedback mechanism commonly used in industrial control systems. \textit{Process variable} and \textit{setpoint} are two core concepts in PID control. The process variable stands for the current status of the system. The setpoint is the target for this automatic control system to reach. The goal of PID control is to minimize the error between process variable and setpoint by adjusting system inputs. The controller output $u(t)$ is defined as follows:

\begin{equation}
\label{eq:pid-output}
u(t) = {K_p}e(t) + {K_i}\int_0^t {e(\tau )d\tau }  + {K_d}\frac{d}{{dt}}e(t) \: ,
\end{equation}
where $e(t)$ represents the error between process variable and setpoint at time $t$. $K_p$, $K_i$, and $K_d$ here are tuning parameters representing the proportional gain, integral gain and derivative gain respectively. Proportional part directly relates to the change of the process variable, and is also the main factor to adjust the process variable towards setpoint. There might be oscillations and steady-state errors in a pure proportional system, and they can be reduced or eliminated by adding the integral part. The appearance of derivative part is to predict future errors, so that the system tends to become steady early and quickly. The result of (\ref{eq:pid-output}) is used to manipulate the system input of next moment to adjust process variable towards setpoint.

As an effective and flexible control technique, PID control has been used to solve all kinds of control problems. In the area of video coding, we notice that PID is utilized to design rate control algorithms by many papers. For instance, in \cite{Wong04} a PID-based real time rate control scheme is proposed to trade-off between spatial and temporal quality and smooth the video quality between frames; in \cite{Yang10}, the authors designed an incremental rate control algorithm for H.264/SVC, in which the PID method is used to provide robust buffer control for each layer. We also notice that some researchers have proposed theoretical model or middle-ware framework for QoS adaptation \cite{Li98}\cite{Li99}, with PID as the basic control concept. However, we have not found any paper that integrates PID method into the quality control of video streaming. While rate control of video coding and quality control of video streaming are two different problems, they do share some common properties, such as the buffer mechanism and the requirement for smoothness. That inspires us to design a PID-based quality control algorithm and utilize it to deliver best video quality with least quality fluctuation.

In this section, we first introduce the \textit{quality level} concept to discretization the bitrate and quality of scalable video. Then we define the process variable used in our PID-based quality control algorithm. After that, the algorithm is formulated and explained in detail, followed by the brief discussion of parameter selection.

\subsection{Quality Level}
\label{subsec:quality-level}

The video quality is a continuous value. In practical operation, it is not possible to control it at an arbitrary precision. So we propose a \textit{quality level} concept as the discrete description of the video quality. When the video quality needs to be adjusted, we simply increase or decrease the quality level. Each quality level corresponds to a certain bitrate. A higher quality level corresponds to a higher bitrate and vice versa. The number of quality levels and how they are mapped to sub-streams with different bitrates depends on actual requirement or implementation. The more quality levels are defined, the more precisely the control algorithm can adjust bitrate to follow the bandwidth change. As pointed out in section \ref{sec:intro}, simulcast streaming systems can only have limited quality levels while SVC streaming systems can define quality levels at a much finer granularity.

\subsection{Process Variable Selection}
\label{subsec:variable}

In our PID-based quality control algorithm, the process variable is called \textit{actual\_check interval ratio}, which is defined as follows.

In DSS, two timelines are important. Push timeline indicates the time of pushing video data packets to streaming buffer, and play timeline indicates the time these data packet should be played, i.e., the presentation time stamp (often seen as PTS) of each packet. Their relationship is shown in Fig. \ref{fig:intervals}. The program will check the timelines periodically, and, in the default quality control algorithm of DSS, use the packet delays to decide whether quality change is needed. The two intervals shown in Fig. \ref{fig:intervals}, i.e., check interval and actual interval, are worth notice and may provide useful information. In the ideal situation, during each check interval, the server pushes an amount of data that will actually play for a period of time equal to that check interval, i.e., \textit{actual\_interval} = \textit{check\_interval}. If \textit{actual\_interval} is smaller than \textit{check\_interval}, it means that less data is pushed to the client, and the pushing is slowed down because bandwidth is relatively low at this time. On the other hand, if \textit{actual\_interval} is larger than \textit{check\_interval}, it indicates the bandwidth condition is good and data is being pushed quickly to the client. The ratio of these two intervals, i.e., \textit{actual\_check interval ratio}, is in direct proportion to the ratio of the data rate appropriate for bandwidth and the current pushing data rate.

The \textit{actual\_check interval ratio} is suitable for quality control because: 1) this ratio directly reflects the mismatch of current pushing data rate and the bandwidth, and by adjusting data rate according to it, this ratio can be used to accurately change video quality; 2) the desired value of this ratio is 1.0 by definition so we don't need to find the optimized setpoint by mathematical methods or experiments; and 3) it is easy to compute and implement in practical systems.

\begin{figure}[t]
\centering
\includegraphics[width = 0.9\linewidth]{intervals.jpg}
\caption{Two timelines in Darwin Streaming Sever (DSS) \label{fig:intervals}}
\end{figure}

\subsection{Model Formulation}
\label{subsec:model}

As is introduced above, the \textit{actual\_check interval ratio} serves as the process variable in this PID-based quality control algorithm. In normal PID control, the controller output is calculated using the proportion, integral and differential of the error between the process variable and the setpoint, as shown in (\ref{eq:pid-output}). Considering that our process variable is a ratio and the corresponding setpoint is 1, we make a little modification to the general PID controller and obtain a ratio-based model. In this model, the ratio is directly used to calculate the controller output, and all subtraction operations in original PID equations have been changed to division operations to keep the correctness, as follows:

\begin{equation}
\label{eq:ut}
{u_t} = {K_p}E_p^t + {K_i}E_i^t + {K_d}E_d^t ,
\end{equation}

\begin{equation}
\label{eq:ep}
E_p^t = \frac{{actual\_interva{l_t}}}{{check\_interva{l_t}}} ,
\end{equation}

\begin{equation}
\label{eq:ei}
E_i^t = \frac{{long\_actual\_interva{l_t}}}{{long\_check\_interva{l_t}}} ,
\end{equation}

\begin{equation}
\label{eq:ed}
E_d^t = E_p^t/E_p^{t - 1} ,
\end{equation}

\begin{equation}
\label{eq:long-actual}
long\_actual\_interva{l_t} = \sum\limits_{\tau = {T_l}}^t {actual\_interva{l_\tau}} ,
\end{equation}

\begin{equation}
\label{eq:long-check}
long\_check\_interva{l_t} = \sum\limits_{\tau = {T_l}}^t {check\_interva{l_\tau}} .
\end{equation}


In (\ref{eq:ut}), $K_p$, $K_i$, and $K_d$ indicate the tuning parameters for proportional, integral and derivative parts respectively, and $E_p^t$, $E_i^t$, $E_d^t$ stand for the corresponding observed value for each part, which are defined in (\ref{eq:ep}) - (\ref{eq:long-check}); the controller output $u_t$ is utilized to calculate an appropriate data rate and further to determine which quality level we should transmit (see Algorithm \ref{algo:control} for more details).

In (\ref{eq:long-actual}) and (\ref{eq:long-check}), $T_l$ stands for the last quality change time. Theoretically, the integral part should be recorded and calculated from the system start. In practice, however, bandwidth may vary significantly during the transmission. If the integral part was recorded for too long time, it may not reflect the real network status and may slow down the reaction for better quality level. A compromise here is to choose a relatively long time, i.e., the time from last quality change till now, for the integral part calculation.

This ratio-based model is more simple and effective for the chosen process variable and setpoint. And note that, since the controller output ($u_t$) is also a ratio, it should be used as a multiplier to manipulate the system input, i.e., the pushing data rate.

The whole process of this algorithm is described in Algorithm \ref{algo:control}. Compared to other scheduling strategies, this quality control algorithm has several advantages. First, this algorithm does not just rely on current packet delay or information at fixed time point, so quality change may occur at any proper time. Second, since the model has taken prediction into account, we can actually decide whether the bandwidth will be high or low enough for the quality level to change, thus avoiding video quality fluctuation. Third, in this algorithm it's not necessary to change one quality level at a time. This enables fast quality drop when bandwidth suddenly decreases and fast quality rise when system starts, resulting in a seamless experience.

\begin{algorithm}
\caption{PID-based quality control algorithm}
\label{algo:control}
\begin{algorithmic}
    \STATE before packet sent
    \STATE check\_interval = curr\_time -- last\_check\_time
    \STATE actual\_interval = curr\_media\_time -- last\_check\_media\_time
    \STATE long\_check\_interval += check\_interval
    \STATE long\_actual\_interval += actual\_interval
    \STATE calculate $E_p^t$, $E_i^t$, $E_d^t$ according to Eq. (\ref{eq:ep}) - (\ref{eq:ed})
    \STATE output = ${K_p}E_p^t + {K_i}E_i^t + {K_d}E_d^t$
    \STATE new\_bitrate = output * curr\_bitrate
    \STATE new\_level = get\_level(new\_bitrate, bitrate\_of\_level[])
    \IF {quality level changed}
    	\STATE long\_check\_interval = 0
    	\STATE long\_actual\_interval = 0
    	\STATE curr\_bitrate = bitrate\_of\_level[new\_level]
    \ENDIF
    \STATE send packet according to new quality level
  \end{algorithmic}
\end{algorithm}


\subsection{Parameter Selection}
\label{subsec:parameter}

Ziegler--Nichols method \cite{Ziegler42} is used to tune $K_p$, $K_i$, and $K_d$ to obtain better performance of the PID control system. This method is performed by setting integral and derivative parameters to zero and then tuning $K_p$ to a value $K_u$ until output begins to oscillate with constant amplitude. Assuming the oscillation period is $T_u$, we set $K_p = 0.6K_u$, $K_i = 2K_u/T_u$, and $K_d = K_uT_u/8$. $K_p$, $K_i$, and $K_d$ are then normalized to get the final parameters. In the following experiments, parameters are chosen as $K_p = 0.22$, $K_i = 0.73$, $K_d = 0.05$ by this method. Note that, in the quality control algorithm, only the data rate and the bandwidth are considered, not the video content, so once the parameters are tuned they should apply well to different video streams.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Optimized Bitstream Extraction Based On Linear Error Model}
\label{sec:bit-extraction}

Once the quality control algorithm determines an appropriate bitrate and sets a quality level accordingly, the system will send a packet only belonging to this new quality level (as described at the end of Algorithm \ref{algo:control}). For SVC videos, that means to extract a subset of packets from the whole bitstream. How to optimally choose this subset to achieve minimum distortion under the given bitrate is the key point of bitstream extraction problem. In this section, we propose a linear error mode and a greedy-like algorithm to solve this problem.

\subsection{Linear Error Model for Quality Scalable Video}
\label{sec:model}

In H.264/AVC, the decoding process involves a linear feature described in \cite{Winken08}, neglecting any rounding, clipping, and deblocking filtering operation. According to this feature, the main steps in H.264/AVC coding -- prediction, transform and quantization -- are proximately linear operations, and the whole coding process can be expressed in a matrix format as follows:
	\begin{equation}
	\label{eq:linear}
s = {\rm\bf M}s + {\rm\bf T}c + p \: ,
	\end{equation}
It means, the reconstructed samples of a GOP (Group of Pictures), denoted by $s$, can be viewed as a linear combination of previously reconstructed samples in the GOP, the residual samples, and a static predictor. In (\ref{eq:linear}), $c$ refers to the transform coefficient values and $p$ is a static predictor; $M$ and $T$ are square matrices such that the product $M$s gives the MCP (Motion Compensated Prediction) signal and $Tc$ gives the residual values. The actual values of $M$ depend on the selected macroblock types, reference indices and motion vectors, whereas the actual values of $T$ depend on the chosen QP (Quantization Parameter) values.

We apply the above linear decoding model to the case of quality scalability of SVC and get a linear error model. According to (\ref{eq:linear}), for a bitstream just containing the base layer, we have:
	\begin{equation}
	\label{eq:base0}
s_{B} = {\rm\bf M}s_{B} + {\rm\bf T}_{B}c_{B} + p \: ,
	\end{equation}
where the subscript $B$ indicates the base layer variables. In quality scalability, the enhancement is mainly the refinement of transform coefficients, so for a bitstream containing an enhancement packet set $I_1$, the reconstruction relationship can be expressed as:
	\begin{equation}
	\label{eq:subset1}
s_{I_1} = {\rm\bf M}s_{I_1} + {\rm\bf T}_{B} c_{B} + \Big( \sum_{i \in I_1}{\rm\bf T}_i c_i \Big) + p \: ,
	\end{equation}
where $i$ refers to an enhancement packet as an element of $I_1$. $c_i$ is a vector containing coefficients within the enhancement packet $i$. ${\rm\bf T_i}$ is the transform matrix depending on the QP value of $i$. ${\rm\bf T}_i c_i$ gives the residual sample values decoded from $i$.

Similarly, for another bitstream containing an enhancement packet set $I_2$, we have
	\begin{equation}
	\label{eq:subset2}
s_{I_2} = {\rm\bf M}s_{I_2} + {\rm\bf T}_{B} c_{B} + \Big( \sum_{i \in I_2}{\rm\bf T}_i c_i \Big) + p \: .
	\end{equation}

Suppose $I_1$ is a subset of $I_2$, their reconstruction difference can be obtained by (\ref{eq:subset2}) - (\ref{eq:subset1}):
	\begin{equation}
	\label{eq:minus1}
(s_{I_2} - s_{I_1}) = {\rm\bf M}(s_{I_2} - s_{I_1}) + \Big( \sum_{i \in I_2}{\rm\bf T}_i c_i - \sum_{i \in I_1}{\rm\bf T}_i c_i \Big) \: ,
	\end{equation}
	\begin{equation}
	\label{eq:minus2}
\Rightarrow e = s_{I_2} - s_{I_1} = ({\rm\bf I - M})^{-1} \Big( \sum_{i \in I_2}{\rm\bf T}_i c_i - \sum_{i \in I_1}{\rm\bf T}_i c_i \Big) \: .
	\end{equation}
	
Particularly, if the difference of $I_2$ and $I_1$ is a single enhancement packet $j$, i.e. $I_2 \setminus I_1 = \{j\}$, then according to (\ref{eq:minus2}), the difference of the two reconstruction vectors can be written as
	\begin{equation}
	\label{eq:error_j}
e_j = ({\rm\bf I - M})^{-1} {\rm\bf T}_j c_j \: .
	\end{equation}
	
Obviously, $e_j$ is only determined by packet $j$, and has no relation with other enhancement packets. This value is called the ``error vector'' of packet $j$, which represents the pixel value error caused by discarding the packet $j$. We can obtain the error vector of each enhancement packet by subtraction between video sequences reconstructed from two enhancement packet subsets $I_1$ and $I_2$, with $I_1 \subseteq I_2$ and $I_2 \setminus I_1 =\{j\} $. Once all packets' error vectors are obtained, the distortion caused by discarding a group of packets can be estimated by adding up the error vector of each packet in the group.

The above model is called Linear Error Model (LEM). Note that in equations (\ref{eq:base0})-(\ref{eq:subset2}) the value of M and p remain the same, since in the case of quality scalability the enhancement packets are generated only by manipulating the transform coefficients, and not interfered with the motion compensation and static prediction.  This argument no longer holds for the other scalable dimensions, so the model does not simply apply for those cases. Further research and modification of this linear model for the spatial or temporal scalability would be our future work.


\subsection{Error Vector Acquisition}
 It would need too many decoding times to get the error vectors of all enhancement packets if we calculate them one at a time. In order to acquire error vectors of all enhancement packets efficiently, we separate all enhancement packets into several groups, such that in each group multiple error vectors can be obtained independently at the same time.
 
 \begin{figure}[h]
 \centering
 \includegraphics[width = 0.9\linewidth]{GOPStructure.jpg}
 \caption{Group of pictures (GOP) in SVC \label{fig:GOP_Structure}}
 \end{figure}
 
 Consider a video bitstream with 8-frame GOPs (Group of Pictures) shown in Fig. \ref{fig:GOP_Structure}. Base layer packets are colored black, and enhancement packets with the same color are allocated in one group. In each group, the enhancement packets' error vectors can be calculated simultaneously, since the pixel errors they caused are not interfered with each other. For example, the loss of packet 8 would bring about distortion only in frame 1, 2 and 3, while packet 10 only in frame 5, 6 and 7(frame number starts from 0). So we can do subtraction for this group, for one time, to gain error vectors $e_{8}$ and $e_{10}$, for both packets 8 and 10, as well as peer packets in all other GOPs. Note that these error vectors are highly sparse ones, because the discarding of a single enhancement packet can bring distortion only to a limited number of frames. To acquire all error vectors, the number of required extraction and decoding is approximately the number of enhancement layers $(L_Q - 1)$ times the temporal layer number $L_T$. For the example in Fig. \ref{fig:GOP_Structure}, $L_Q = 3$ and $L_T = 4$, so the theoretical extraction-and-decoding number is $(3 - 1) \times 4 = 8$. However, we have to do the same manipulation for $L_Q - 1 = 2$ more times, to dissociate the distortion impact of ``key frame''\cite{H264Overview} (e.g. frame 0, 8, 16, etc.) packets. The loss of one enhancement packet in a key frame would bring distortion to two neighboring GOPs. As an instance, the loss of packet 4 would propagate drift into frame 1 to 15, which would interfere with the distortion impact of packets in frame 0 and 16 (packet 1, 2 and 19, 20). So key frame enhancement packets within the same quality layer (e.g. packet 2, 4 and 20) should be allocated in two groups -- one for key frame packets of even number GOPs (packet 2 and 20), the other for those of odd number GOPs (packet 4). So the actual number of extraction and decoding for error vector acquisition is $(L_Q - 1) \cdot (L_T + 1)$, approximately the same with JSVM reference software\cite{H264Overview}. Since computation is mainly consumed with this decoding in our bitstream extraction algorithm, the computation complexity has no obvious promotion compared with JSVM.
 
\subsection{Distortion Estimation And Model Verification}

Based on the linear error model described above, we can obtain error vectors of all enhancement packets. Then we can estimate the distortion caused by discarding any set of enhancement packets, by adding up the error vector of each packet in that set.

For example, consider a video sequence decoded from a sub-stream which is extracted by discarding packet set $I_x$. The error between this sequence and the original sequence can be estimated as

	\begin{equation}
	\label{eq:subset_error}
e(I_x) = e_{full} + \sum_{i \in {I_x}} e_i \: . 
	\end{equation}
Eq. (\ref{eq:subset_error}) has taken into consideration the error between the video sequence decoded from full enhancement packets and the original sequence, written as $e_{full}$.

To verify the linear error model, we conduct an experiment where some random sets of enhancement packets are removed from a video bitstream, and the distortion estimated by the linear error model are compared with the actual distortion. Experimental result of the sequence {\em Foreman} is partly shown in Fig. \ref{fig:linear_verification}. The horizontal axis stands for sample point numbers of those random selections, and the vertical axis for MSE measurement. The solid line represents the actual MSE of a randomly extracted substream, and the dot line shows the estimated MSE using our Linear Error Model. A 0.6\% maximum relative error of MSE demonstrates the accuracy of the proposed model.

\begin{figure}[h]
\centering
\includegraphics[width = 0.9\linewidth]{LinearVerification.jpg}
\caption{Result of SVC Linear Error Model verification \label{fig:linear_verification}}
\end{figure}


\subsection{Priority Assignment and Bitstream Extraction}
\label{subsec:priority}

In this subsection, we utilize the Linear Error Model to enable R-D optimized bitstream extraction. Since finding the global optimal solution of the bitstream extraction problem is impractical, our bitstream extraction algorithm uses a greedy method \cite{GreedyAlgo} to get a sub-optimal solution. Similar to the greedy solution of the ``0-1 Knapsack Problem", every time a packet is to be discarded, we choose the packet that has the minimal R-D impact. A packet's R-D impact is mathematically measured by:
	\begin{equation}
	\label{eq:rd_impact}
\Phi_{i} = \dfrac{\partial D}{\partial R} \: ,
	\end{equation}
where $\partial D$ represents the distortion change brought by discarding this packet, and $\partial R$ is the corresponding rate change. $\partial R$ is simply equivalent to the size of this packet, while $\partial D$ needs to be calculated by subtraction of distortions before and after the packet is discarded. 

We simulate a process of discarding all the enhancement packets from a stream, using the above greedy strategy. During this process, the discarding order of a packet is regarded as its priority and recorded. Then the packets' priority values can be stored in the bitstream (either in the priority id field of the NALU header or in separate SEI messages) for real extraction in the future.

The detailed discarding and priority assignment process is described below:
\begin{description}
  	\item[1)] Initially, the sequence error vector, $e_{seq}$, is set to $e_{full}$.
  	\item[2)] Within the packets that can be discarded, find the packet $m$ having the least RD impact on the sequence, \textit{i.e. }
	\begin{equation}
	\label{eq:R-D_impact_m}
	\Phi_m = \min_{i \in I_{top}} \Phi_i \: ,
	\end{equation}
	where $I_{top}$ stands for the top layer packets, those currently able to be discarded. The RD impact of a packet is calculated based on (\ref{eq:rd_impact}), as follows: 
	\begin{equation}
	\label{eq:R-D_impact_i}
	\Phi_i = \dfrac{\partial D}{\partial R} = \dfrac{PSNR(e_{seq}) - PSNR(e_{seq} + e_i)}{SIZE(i)} \: ,
	\end{equation}
	where $PSNR(*)$ means to obtain PSNR from the error vector, and $SIZE(i)$ is the size of packet $i$.
  	\item[3)]The packet, $m$, is then removed from the bitstream, and its error vector is added to the sequence's error vector, \textit{i.e.}
  	\begin{equation}
  	\label{eq:error_update}
  	e_{seq} = e_{seq} + e_m \: .
  	\end{equation}
  	\item[4)]The process from 2) to 3) is repeated until all enhancement packets are discarded, and every packet is assigned a priority value according to the removing order.
\end{description}

For long video sequences, an optimization window is usually needed, and the priority assignment and bitstream extraction is conducted independently in each window. The computational complexity of this priority assignment algorithm is $O(K^2)$, with $K$ being the number of frames involved in the priority assignment process, \textit{i.e.}, the size of the optimization window. Note that this computation complexity is negligible compared with the decoding process needed in the error vector acquisition.

\subsection{The No-Reference Case}
\label{subsec:noref}
In some scenarios, the priority assignment and bitstream extraction needs to be conducted without access to the original YUV sequence. For example, if the bitstream extraction is not done at the encoding side, it's most likely that the original sequence is not available. This would make the bitstream extraction a more difficult problem, since the distortion is harder to obtain for lacking of reference signal. Comparing to the problem of SVC bitstream extraction with reference, this kind of ``no-reference bitstream extraction'' problem is actually more frequently encountered in real practice. In this subsection, we handle this no-reference problem as well and modify the proposed algorithm to meet the special characteristic caused by lacking of reference.

In the no-reference case, since we do not have access to the original sequence, we can not get the error between the video sequence decoded from full enhancement packets and the original sequence, which is $e_{full}$ used above. A straightforward idea is to set $e_{full}$ to zero, meaning we calculate distortion with respect to the fully reconstructed signal, rather than to the original sequence. However, simply doing so causes the algorithm to perform badly in experiments. We find that, since discarding some enhancement packets will not bring much significant error relative to the fully reconstructed signal, the calculated PSNR values are too large to well represent the real distortion. To address this issue, instead of calculating PSNR, we directly use MSE of all pixels as the distortion criteria in the priority assignment algorithm. This proves to be a simple and effective solution, and the extraction performance turns out to be much better.

We have presented experimental results for the case where reference original sequence is available in our previous work \cite{Zhang12}, so this paper will include only experimental results for the no-reference case in the following section.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Results}
\label{sec:experiment}

To implement our proposed scalable streaming system requires the combination of the PID-based quality control algorithm and the optimized bitstream extraction method. The former determines the current bitrate to follow the bandwidth change, and the latter will ensure the sub-stream with the best possible quality is sent under that bitrate constrain. They work together to construct a system that delivers best quality of experience for the users. We have integrated the PID-based quality control algorithm into DSS. However, the integration of the proposed bitstream extraction method needs more engineering work and has not been accomplished. Therefore, in this section, we present separate experiments to demonstrate the advantage of each proposed solution.

\subsection{Experiments for Quality Control}

For simplicity and intuition, we combine the enhancement layers in the tested SVC video stream to construct quality levels (introduced in \ref{subsec:quality-level}) used in the quality control algorithm. The video stream is divided into several sub-streams, each of which is identified by the quality and temporal layer it contains, as illustrated in Table \ref{tab:sub-stream} (there are 3 layers in each scalability dimension; spatial scalability is not enabled). The quality level is defined as the sum of all sub-streams with ID equal or less than the level number. For example, quality level 3 would contain all sub-streams from 0 to 3, thus would include all temporal layers, but only the quality base layer 0. The tested stream has 9 quality levels from 0 to 8 (Table \ref{tab:sub-stream}), and a maximum bit rate of 1587 kbps at level 8. 

\begin{table*}[t]
\centering
\caption{Sub-stream ID}
\label{tab:sub-stream}
\begin{tabular}{c|*{8}{p{1.2cm}<{\centering}|}{p{1.2cm}<{\centering}}}
	\hline\hline
	  Sub-stream ID   & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
	Quality Layer ID  & 0 & 0 & 0 & 1 & 1 & 1 & 2 & 2 & 2 \\ \hline
	Temporal Layer ID & 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1 & 2 \\ \hline
\end{tabular}
\end{table*}

We simulate network fluctuation by adjusting bandwidth around a certain level. We set this level from 400 to 1400 kbps to reflect different average bandwidth. All the experiments are conducted in Visual C++ 6.0 (with DSS as the software platform) and the bandwidth control is implemented by NetLimiter 3 \cite{Netlimiter}. The baseline algorithm in the comparison refers to the packet delay feedback (PDF) algorithm in the original DSS.

First of all, we conduct some preliminary improvement experiments using only proportional part or integral part. Since they are directly related to the short term error and long term error respectively, we call them Short Term Prediction (STP) and Long Term Prediction (LTP). Fig. \ref{fig:performance-all} shows the experimental results of these two control algorithms and the baseline algorithm. In the figures, the video quality is measured by the quality level defined in the beginning of this section, and quality smoothness is indicated by the variance of the quality levels along time. We can conclude that STP provides the best average quality level at the expense of high quality variance. This can be easily explained since this quality control strategy closely follows the bandwidth fluctuation. In contrast, LTP keeps a relatively low quality variance at a little cost of average video quality. Although it is not as good as STP in average quality, it still outperforms the baseline algorithm by 7.9\%.

Since STP and LTP have their own limitations, we implement the PID-based quality control algorithm, which can both reduces quality variance and improves average quality level. From the result shown in Fig. \ref{fig:performance-two}, we can conclude that when integrated with integral part and derivative part, the effect of proportional part is not as aggressive as in STP. An obvious proof can be found in Fig. \ref{fig:variance-two}, which clearly shows that the proposed PID quality control algorithm keeps a lower quality variance compared to PDF algorithm. Table \ref{tab:improvement} lists the statistical experimental results for these four quality control algorithms, in which PID-based control algorithm has shown its advantage over the others, especially in reducing the quality fluctuation. It can be seen that, compared to PDF, the PID-based quality control algorithm improves 8.6\% in video quality with 24.8\% reduction in quality fluctuation. The video quality fluctuation of the four control algorithms, when available bandwidth fluctuates around 800 kbps, is shown in Fig. \ref{fig:fluctuation}, from which we can see a more stable video quality in the proposed PID quality control algorithm.

\begin{figure*}[t]
\subfloat[Average quality level of different control algorithms]{
\includegraphics[width=0.5\textwidth]{quality-all.jpg}
\label{fig:quality-all}}
\subfloat[Variance of quality level of different control algorithms]{
\includegraphics[width=0.5\textwidth]{variance-all.jpg}
\label{fig:variance-all}}
\caption{Comparison of the long/short time prediction and the PDF algorithm in DSS}
\label{fig:performance-all}
\end{figure*}

\begin{figure*}[t]
\centering
\subfloat[Variance of quality level of PID and PDF control algorithms]{
\includegraphics[width=0.5\textwidth]{quality-two.jpg}
\label{fig:quality-two}}
\subfloat[Average quality level of PID and PDF control algorithms]{
\includegraphics[width=0.5\textwidth]{variance-two.jpg}
\label{fig:variance-two}}
\caption{Comparison of the proposed PID algorithm and the PDF algorithm in DDS}
\label{fig:performance-two}
\end{figure*}


\begin{table*}[t]
\centering
\caption{Improvement of Different Quality Control Schemes}
\label{tab:improvement}
\begin{tabular}[b]{p{4.2cm}<{\centering}|p{4.2cm}<{\centering}|p{4.2cm}<{\centering}}
\hline \hline
Quality control scheme & Average quality level & Quality variance \\ \hline
Packet delay feedback (PDF) & 0.0\% & 0.0\% \\ \hline
Short term prediction (STP) & \textbf{+13.5\%} & +38.5\% \\ \hline
Long term prediction (LTP) & +7.9\% & -17.2\% \\ \hline
PID based control scheme(PID) & +8.6\% & \textbf{-24.8\%} \\ \hline
\end{tabular}
\end{table*}


\begin{figure}[t]
\centering
\includegraphics[width = 0.9\linewidth]{fluctuation.jpg}
\caption{Video quality fluctuation with time \label{fig:fluctuation}}
\end{figure}

\subsection{Experiments for Bitstream Extraction}

We compare the performance of the proposed bitstream extraction method with that of JSVM 9.16.

In our experiments, all test bitstreams are encoded with the JSVM encoder, where the standard hierarchical B coding structure and CABAC entropy coding are used. Each bitstream contains one base layer and a quality enhancement layer, with quantization parameters QP = 33 and QP = 27, respectively. The enhancement layer is further divided into 2 MGS layers by configuring the MGS vector to separate the transform coefficients into two groups (containing 4 and 12 coefficients respectively). For each test bitstream, ten bitrate points (one with all enhancement packets, one with only the base layer packets, and 8 points between) are chosen for extraction. For each bitrate point, the extraction is conducted using the bitstream extractors in JSVM, with and without quality layer (denoted as JSVM QL and JSVM Basic, respectively), and the proposed method. The size of the optimization window in the proposed method is set to 4 GOPs, with a GOP size of 8. All of the eight SVC standard sequences with CIF resolution are considered at 30FPS and tested in our experiments.

The performance comparisons for City, Foreman, Harbour, and Soccer are shown in Fig. \ref{fig:performance}. It can be seen that the R-D curves of the proposed method are always on the top. For each sequence, the maximum and average PSNR gain through all 10 bitrate points are calculated and listed in Table \ref{tab:results}, which shows that our extraction method can achieve a significant performance gain compared with JSVM.

Among other bitstream extraction methods besides that of JSVM, the work in \cite{Maani09} achieves much better performance than JSVM QL, and even better than ours. However, the method of \cite{Maani09} needs more computation in order to train robust model parameters for different sequences, while the complexity of our method is always the same with JSVM QL.

\begin{comment}[8 mini-figures]
\begin{figure*}[t]
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width = \linewidth]{City.jpg}
\caption{City \label{fig:City}}
\end{minipage}
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width = \linewidth]{Foreman.jpg}
\caption{Foreman \label{fig:Foreman}}
\end{minipage}
\end{figure*}

\begin{figure*}[t]
\begin{minipage}{0.5\linewidth}
\centering
\includegraphics[width = \linewidth]{Harbour.jpg}
\caption{Harbour \label{fig:Harbour}}
\end{minipage}
\begin{minipage}{0.5\linewidth}
\centering 
\includegraphics[width = \linewidth]{Soccer.jpg} 
\caption{Soccer \label{fig:Soccer}}
\end{minipage} 
\end{figure*}

\end{comment}

\begin{figure*}[t]
\centering
\subfloat[City]{
\includegraphics[width=0.5\textwidth]{City.jpg}
\label{fig:City}}
\subfloat[Foreman]{
\includegraphics[width=0.5\textwidth]{Foreman.jpg}
\label{fig:Foreman}}
\qquad
\subfloat[Harbour]{
\includegraphics[width=0.5\textwidth]{Harbour.jpg}
\label{fig:Harbour}}
\subfloat[Soccer]{
\includegraphics[width=0.5\textwidth]{Soccer.jpg}
\label{fig:Soccer}}
\caption{Performance of three bitstream extraction methods for various CIF sequences}
\label{fig:performance}
\end{figure*}

\begin{table*}[t]
\centering
\caption{Algorithm Performance: Luma PSNR Gain Compared with JSVM}
\label{tab:results}
\begin{minipage}{0.95\linewidth}
% \renewcommand{\thefootnote}{\thempfootnote}
\centering
\begin{tabular}{c|c|p{1.2cm}<{\centering}|p{1.2cm}<{\centering}|p{1.2cm}<{\centering}|p{1.2cm}<{\centering}| 
p{1.2cm}<{\centering}|p{1.2cm}<{\centering}|p{1.2cm}<{\centering}|p{1.2cm}<{\centering}}

%% |l|l| to left justify each column entry
%% |c|c| to center each column entry
%% use of \rule[]{}{} below opens up each row 

\hline \hline
\multicolumn{2}{c|}{Sequence} &
{\em Bus} & {\em City} & {\em Crew} & {\em Football} & {\em Foreman} & {\em Harbour} & {\em Mobile} & {\em Soccer} \\ \hline 

\multirow{2}{*}{JSVM QL\footnote{\label{footnote:JSVM_QL} Comparing the proposed algorithm with JSVM QL} (dB)}
& Max\footnote{\label{footnote:max} Maximum PSNR gain through all bitrate constraints} & 0.37 & 0.50 & 0.13 & 0.22 & 0.23 & 0.19 & 0.25 & 0.44 \\ \cline{2-10}
& Ave\footnote{\label{footnote:ave} Average PSNR gain through all bitrate constraints} & 0.11 & 0.11 & 0.05 & 0.12 & 0.05 & 0.05 & 0.06 & 0.13 \\ \hline

\multirow{2}{*}{JSVM no QL (dB)}
& Max & 0.50 & 0.83 & 0.32 & 0.29 & 0.50 & 0.34 & 0.61 & 0.53 \\ \cline{2-10}
& Ave & 0.18 & 0.37 & 0.20 & 0.15 & 0.22 & 0.15 & 0.25 & 0.29 \\ \hline

\end{tabular}
\end{minipage}
\end{table*}


\section{Conclusion}
\label{sec:conclusion}

In this paper, we propose an adaptive video streaming system with PID-based quality control algorithm and optimized bitstream extraction. The PID-based quality control algorithm has a flexible mechanism to determine the suitable quality level so that it gives an accurate and swift response to the bandwidth change. Comparing with the original algorithm in DSS, this algorithm has reduced quality fluctuation significantly to improve audience satisfaction. The bitstream extraction method we propose includes a linear error model to estimate the distortion caused by discarding any combination of packets and a greedy algorithm to assign priority to each data packet. The packets' priority values can then be stored in the bitstream and used for R-D optimized extraction. Experimental results show that the proposed method can achieve PSNR gain of up to 0.5 compared to the JSVM QL extractor under the same bitrate constrain, also with the same computational complexity.

The PID-based quality control algorithm of this paper has already been integrated into the online website www.7dlive.com and performs well in automatically adapting to the user's bandwidth fluctuation. This algorithm can also be easily used in other streaming systems, e.g., DASH systems. For the bitstream extraction method, there is future work to be done in the following two directions. First, we strive to integrate the bitstream extraction method into DSS, and combine it with the PID-based quality control to give user adaptive video streaming with best watching experience. Second, since the next generation video coding standard High Efficiency Video Coding (HEVC) \cite{HEVC} adopts the similar coding framework as its predecessor H.264/AVC, we expect to apply this paper's model and approach to the emerging HEVC standard and its scalable extension.


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{DASH}
T. Stockhammer, ``Dynamic adaptive streaming over HTTP: standards and design principles", in {\em Proceedings of the second annual ACM conference on Multimedia systems}, 2011.

\bibitem{SVC}
T.~Wiegand, G.~Sullivan, J.~Reichel, H.~Schwarz, M.~Wien, eds., ``Joint Draft ITU-T Rec. H.264|ISO/IEC 14496-10/Amd.3 Scalable Video Coding'', Joint Video Team, Doc. JVT-X201 Jul. 2007.

\bibitem{SVCOverview}
H.~Schwarz, D.~Marpe and T.~Wiegand, ``Overview of the scalable video coding extension of the H.264/AVC standard'', in {\em IEEE Trans. Circuits. Syst. Video Technol.}, vol. 17, no. 9, pp.~1103-1120, Sept. 2007.

\bibitem{YouTube}
https://www.youtube.com/

\bibitem{SVCPerformance}
M. Wien , H. Schwarz and T. Oelbaum,  ``Performance Analysis of SVC'',  in {\em IEEE Trans. Circuits Syst. Video Technol.}, vol. 17, no. 9, pp.1194-1203. Sep. 2007.

\bibitem{DSS}
http://dss.macosforge.org/

\bibitem{Gao06}
K. Gao, J. Zhai, J. Li and C. Wang, ``Real-Time scheduling for scalable video coding streaming system'', in {\em IEEE Sarnoff Symposium}, Princeton, NJ, pp. 1-4, Mar. 2006.

\bibitem{Schierl10}
Y. Schierl, R. Sanchez, C. Globisch, Hellge, and T. Wiegand, ``Priority-based media delivery using SVC with RTP and HTTP streaming'', in {\em Multimedia Tools And Applications}, vol. 55, no. 2, pp. 227-246, Sep. 2010.

\bibitem{Amonou07}
I.~Amonou, N.~Cammas, S.~Kervadec, S.~Pateux, ``Optimized Rate-distortion Extraction with Quality Layers in the Scalable Extension of H.264/AVC'' in {\em IEEE Trans. Circuits Syst. Video Technol.}, vol.~17, no.~9, pp.~1186--1193, Sep. 2007.

\bibitem{JSVM}
Text of ISO/IEC 14496-4:2001/PDAM 19 Reference Software for SVC, Joint Video Team (JVT) of ISO-IEC MPEG \& ITU-T VCEG, N9195, Sep. 2007.

\bibitem{Sun09}
J.~Sun, W.~Gao, D.~Zhao, W.~Li, ``On Rate-distortion Modeling and Extraction of H.264/SVC Fine-Granular Scalable Video'' in {\em IEEE Trans. Circuits Syst. Video Technol.}, vol.~19, no.~3, pp.~323--336, Mar. 2009.

\bibitem{Maani09}
E.~Maani, A.~K. Katsaggelos, ``Optimized Bit Extraction Using Distortion Modeling in the Scalable Extension of H.264/AVC'' in {\em IEEE Trans. Image Processing}, vol.~18, no.~9, pp.~2022--2029, Sep. 2009.

\bibitem{Zhang12}
W.~Zhang, J.~Sun, J.~Liu and Z.~Guo, ``Optimized bit extraction of SVC exploiting linear error model,'' {\em 2012 IEEE International Symposium on Circuits and Systems}, pp.~1887--1890, Seoul, Korea, May 2012.

\bibitem{PID}
http://en.wikipedia.org/wiki/PID\_controller

\bibitem{Astrom02}
K. J. Astrom, Control System Design, pp 216-219, 2002.

\bibitem{Wong04}
C.W.Wong, O.C.Au and H.K.Lam, ``PID-based real-time rate control'', in {\em IEEE International Conference on Multimedia and Expo}, 1: 221-224, 2004.

\bibitem{Yang10}
J. Yang, Y. Sun, Y. Zhou, S. Sun, ``Incremental rate control for H.264 scalable video coding'', in {\em IEEE Global Telecommunications Conference}, Miami, Florida, Dec. 2010.

\bibitem{Li98}
B. Li and K. Nahrstedt  ``A control theoretical model for quality of service adaptations'', in {\em Proceedings of Sixth International Workshop on Quality of Service}, 1998.

\bibitem{Li99}
B. Li and K. Nahrstedt, ``A control-sased middleware framework for Quality-of-Service adaptations'', in {\em IEEE J. Selected Areas in Comm.}, vol. 17, no. 9, pp. 1632-1650, Sept. 1999.

\bibitem{Ziegler42}
J. B. Ziegler and N. B. Nichols, ``Optimum settings for automatic controllers'', in {\em ASME Trans.}, pp. 759-768, 1942.

\bibitem{Winken08}
M.~Winken, H.~Schwarz, T.~Wiegand, ``Joint Rate-distortion Optimization of Transform Coefficients for Spatial Scalable Video Coding Using SVC'' in {\em Proc. International Conference on Image Processing 2008}.

\bibitem{H264Overview}
T.~Wiegand, G.~J. Sullivan, G.~Bj$\o$ntegaard, A.~Luthra, ``Overview of the H.264/AVC Video Coding Standard'', in {\em IEEE Trans. Circuits Syst. Video Technol.}, vol. 13, no. 7, pp.~560--576, Jul. 2003.

\bibitem{GreedyAlgo}
P.~E.~Black, ``Greedy Algorithm'' in {\em Dictionary of Algorithms and Data Structures} [online], U.S. National Institute of Standards and Technology, Feb. 2005.
\newblock http://www.nist.gov/dads/HTML/greedyalgo.html

\bibitem{Netlimiter}
NetLimiter: http://www.netlimiter.com/

\bibitem{HEVC}
G.~J.~Sullivan, J.-R.~Ohm, W.-J.~Han, and T.~Wiegand, ``Overview of the High Efficiency Video Coding (HEVC) standard'' in {\em IEEE Trans. Circuits Syst. Video Technol.}, vol.~22, no.~12, pp.~16480900091667, Dec. 2012. 

\end{thebibliography}



% that's all folks
\end{document}


